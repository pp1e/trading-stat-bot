import json
import time
from json import JSONDecodeError
from multiprocessing import Process

import telebot
from telebot import types
from bs4 import BeautifulSoup
from pyppeteer import launch
import asyncio


ALEX_DEP = 753
IVAN_DEP = 600
DENIS_DEP = 100
OVERALL_DEP = ALEX_DEP + IVAN_DEP + DENIS_DEP
DATA_FILE = 'data.json'

bot = telebot.TeleBot('6511544558:AAGZOxhdStzt6SLpe14FgSPwJ84ncThxqJw')


def dollarsToNumber(dollars):
    return float(dollars.replace(' ', '').replace('$', '').replace(',', ''))


def percentsToNumber(percents):
    return float(percents.replace('+','').replace('%', ''))


async def scrapData():
    url = 'https://fxmonitor.online/a/17542800?view=pro&mode=2'

    # # Launch the browser
    browser = await launch()

    # Open a new browser page
    page = await browser.newPage()

    # Open our test file in the opened page
    await page.goto(url)

    # Wait for all dynamic data to load
    time.sleep(1)

    # Get page source code
    page_content = await page.content()

    await browser.close()

    soup = BeautifulSoup(page_content, 'lxml')
    return {
        "balance": dollarsToNumber(soup.find('a', id='17542800balance').text),
        "profit": dollarsToNumber(soup.find('span', id='17542800profit_total').text),
        "currentWeekProfit": dollarsToNumber(soup.find('span', id='17542800profit_w').text),
        #"lastWeekProfit": "",
        "profitPercents": percentsToNumber(soup.find('span', id='17542800profit_w_pr').text),
        "currentWeekProfitPercents": percentsToNumber(soup.find('span', id='17542800profit_w_pr').text),
    }


def scrapDataProcess():
    while True:
        with open(DATA_FILE, 'w') as dataFile:
            data = asyncio.run(scrapData())
            dataFile.write(json.dumps(data))
        print('Data was scrapped!')
        time.sleep(60)


def calcAnte(balance, dep):
    return round(balance * (dep / OVERALL_DEP), 2)


def generateStatistic():
    with open(DATA_FILE, 'r') as dataFile:
        data = json.loads(dataFile.read())

    balance = data['balance']
    currentWeekProfit = data['currentWeekProfit']
    profit = data['profit']

    return f"""
** –¢–ï–ö–£–©–ê–Ø –ù–ï–î–ï–õ–Ø **

**–ó–∞—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞ –Ω–µ–¥–µ–ª—é:**
+{data['currentWeekProfitPercents']}% | +${currentWeekProfit}

üîπ**–í–∞–Ω—è: +${calcAnte(currentWeekProfit, IVAN_DEP)}**
–ü–æ–ø–æ–ª–Ω–µ–Ω–∏—è: $0
–°–Ω—è—Ç–∏—è: $0
–¢–µ–∫—É—â–∏–π –±–∞–ª–∞–Ω—Å: ${calcAnte(balance, IVAN_DEP)}
–û–±—â–∞—è –ø—Ä–∏–±—ã–ª—å: +${calcAnte(profit, IVAN_DEP)}

üîπ**–°–∞–Ω—è: +${calcAnte(currentWeekProfit, ALEX_DEP)}**
–ü–æ–ø–æ–ª–Ω–µ–Ω–∏—è: $0
–°–Ω—è—Ç–∏—è: $0
–¢–µ–∫—É—â–∏–π –±–∞–ª–∞–Ω—Å: ${calcAnte(balance, ALEX_DEP)}
–û–±—â–∞—è –ø—Ä–∏–±—ã–ª—å: +${calcAnte(profit, ALEX_DEP)}

üîπ**–î–µ–Ω: +${calcAnte(currentWeekProfit, DENIS_DEP)}**
–ü–æ–ø–æ–ª–Ω–µ–Ω–∏—è: $0
–°–Ω—è—Ç–∏—è: $0
–¢–µ–∫—É—â–∏–π –±–∞–ª–∞–Ω—Å: ${calcAnte(balance, DENIS_DEP)}
–û–±—â–∞—è –ø—Ä–∏–±—ã–ª—å: +${calcAnte(profit, DENIS_DEP)}

**–í—Å–µ–≥–æ:** ${OVERALL_DEP} -> ${balance}

[–°–õ–ï–î–ò–¢–¨](https://fxmonitor.online/u/UQEvKqKD?view=pro)
        """

@bot.message_handler(commands=['start'])
def start(message):
    markup = types.ReplyKeyboardMarkup(resize_keyboard=True)
    statBtn = types.KeyboardButton("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É")
    markup.add(statBtn)
    bot.send_message(message.chat.id, "–Ø —Ä–æ–±–æ—Ç-–¥–æ–ª–±–æ–µ–±!ü§ñ", reply_markup=markup)


@bot.message_handler(func=lambda message: True)
def echo_message(message):
    try:
        if message.text == "–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É":
            bot.send_message(message.chat.id, generateStatistic(), parse_mode='Markdown')
        else:
            bot.send_message(message.chat.id, '–∏–¥–∏ –Ω–∞—Ö—É–π')
    except JSONDecodeError:
        bot.send_message(message.chat.id, '–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö! –ü–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑')



# chromeDriver = ChromeDriverManager().install()
# print(chromeDriver)
# service=ChromeService(chromeDriver)
# print(service)
# driver = webdriver.Chrome(service=service)
#
# driver.get(url)
# htmlText = driver.page_source
#
# print(htmlText)
# soup = BeautifulSoup(htmlText, 'lxml')
# print(soup.find('a', id='17542800profit_d'))

#data = asyncio.run(scrapData())

# print(asyncio.run(scrapData()))
scrapProcess = Process(target=scrapDataProcess)
scrapProcess.start()
bot.polling(none_stop=True, interval=0)
